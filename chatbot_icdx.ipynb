{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--ghr1MRcs97"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dataclasses\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/chatbot_dataset.csv\"\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "collapsed": true,
        "id": "1l5io_9hd4hB",
        "outputId": "12088be6-8e2f-4209-f9ea-f16924e8105f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"User ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"aP1dnv8AHN\",\n          \"KjUW1iIEnc\",\n          \"tfoHqB59E9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Utterance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Most recognize blue ago miss top face success.\",\n          \"Two Congress action old machine benefit.\",\n          \"Yes back alone sport true.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bot Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Natural student policy somebody reality. Agree heart this child how country.\",\n          \"From however rule training. Operation itself exist use service.\",\n          \"Debate nation series often me husband. Address future option everyone community.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2023-10-31 18:02:07\",\n          \"2023-10-31 18:02:06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context/Session ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"f31c583f-2909-4f5c-940c-47822398460d\",\n          \"0b72b949-2a64-4d1d-a82c-4cc4c2c4495b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Entities\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"location\",\n          \"date\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Feedback\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conversation Outcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"incomplete\",\n          \"specific outcome\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Profile\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9386,\n        \"samples\": [\n          \"Summer Wilson\",\n          \"Thomas Meyer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel/Platform\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"mobile app\",\n          \"email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Chinese\",\n          \"French\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Emotion/Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"frustrated\",\n          \"happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"London\",\n          \"Los Angeles\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Segment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"returning customers\",\n          \"premium users\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44b101a1-b4ca-4732-8f70-02862e8112c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>User Utterance</th>\n",
              "      <th>Bot Response</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Context/Session ID</th>\n",
              "      <th>Entities</th>\n",
              "      <th>User Feedback</th>\n",
              "      <th>Conversation Outcome</th>\n",
              "      <th>User Profile</th>\n",
              "      <th>Channel/Platform</th>\n",
              "      <th>Language</th>\n",
              "      <th>User Emotion/Sentiment</th>\n",
              "      <th>Location</th>\n",
              "      <th>User Segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uKqYhMMQ5S</td>\n",
              "      <td>Charge bar between follow student.</td>\n",
              "      <td>Important law into large example range. Player...</td>\n",
              "      <td>2023-10-31 18:02:06</td>\n",
              "      <td>4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4</td>\n",
              "      <td>event</td>\n",
              "      <td>negative</td>\n",
              "      <td>incomplete</td>\n",
              "      <td>Annette Henderson</td>\n",
              "      <td>social media</td>\n",
              "      <td>German</td>\n",
              "      <td>confused</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>returning customers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YOonrpgxp9</td>\n",
              "      <td>Bad every reflect huge contain.</td>\n",
              "      <td>Policy argue agree character go recent. When r...</td>\n",
              "      <td>2023-10-31 18:02:06</td>\n",
              "      <td>74c97616-9df6-460d-991d-c6f6f6ae5354</td>\n",
              "      <td>location</td>\n",
              "      <td>neutral</td>\n",
              "      <td>specific outcome</td>\n",
              "      <td>Nicholas Haney</td>\n",
              "      <td>mobile app</td>\n",
              "      <td>Chinese</td>\n",
              "      <td>frustrated</td>\n",
              "      <td>London</td>\n",
              "      <td>returning customers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>V0IwFXGYAg</td>\n",
              "      <td>Glass remember many dog director under.</td>\n",
              "      <td>Total rise unit recent data away. Business air...</td>\n",
              "      <td>2023-10-31 18:02:06</td>\n",
              "      <td>f3034d75-d552-4a6c-8c73-0f6b441a7bdf</td>\n",
              "      <td>event</td>\n",
              "      <td>negative</td>\n",
              "      <td>incomplete</td>\n",
              "      <td>David Smith</td>\n",
              "      <td>website chat</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>excited</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>premium users</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3mtwyCBGqy</td>\n",
              "      <td>Help charge record many talk tough.</td>\n",
              "      <td>Artist today decade. Civil score hospital othe...</td>\n",
              "      <td>2023-10-31 18:02:06</td>\n",
              "      <td>46c7bf6a-1da6-4e27-baf5-a138f1e0a1b2</td>\n",
              "      <td>service</td>\n",
              "      <td>negative</td>\n",
              "      <td>incomplete</td>\n",
              "      <td>Susan Wilson</td>\n",
              "      <td>website chat</td>\n",
              "      <td>English</td>\n",
              "      <td>frustrated</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>new users</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dSQOFGb8Pq</td>\n",
              "      <td>Position not man much material.</td>\n",
              "      <td>Character serve receive interview interest ord...</td>\n",
              "      <td>2023-10-31 18:02:06</td>\n",
              "      <td>2487c6ce-65c1-48a4-a76f-0aa6a1e92dda</td>\n",
              "      <td>service</td>\n",
              "      <td>neutral</td>\n",
              "      <td>specific outcome</td>\n",
              "      <td>Jennifer Harmon</td>\n",
              "      <td>mobile app</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>confused</td>\n",
              "      <td>New York</td>\n",
              "      <td>returning customers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44b101a1-b4ca-4732-8f70-02862e8112c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44b101a1-b4ca-4732-8f70-02862e8112c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44b101a1-b4ca-4732-8f70-02862e8112c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab14dc4c-5071-49f1-8cfa-594fd5c9b875\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab14dc4c-5071-49f1-8cfa-594fd5c9b875')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab14dc4c-5071-49f1-8cfa-594fd5c9b875 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      User ID                           User Utterance  \\\n",
              "0  uKqYhMMQ5S       Charge bar between follow student.   \n",
              "1  YOonrpgxp9          Bad every reflect huge contain.   \n",
              "2  V0IwFXGYAg  Glass remember many dog director under.   \n",
              "3  3mtwyCBGqy      Help charge record many talk tough.   \n",
              "4  dSQOFGb8Pq          Position not man much material.   \n",
              "\n",
              "                                        Bot Response            Timestamp  \\\n",
              "0  Important law into large example range. Player...  2023-10-31 18:02:06   \n",
              "1  Policy argue agree character go recent. When r...  2023-10-31 18:02:06   \n",
              "2  Total rise unit recent data away. Business air...  2023-10-31 18:02:06   \n",
              "3  Artist today decade. Civil score hospital othe...  2023-10-31 18:02:06   \n",
              "4  Character serve receive interview interest ord...  2023-10-31 18:02:06   \n",
              "\n",
              "                     Context/Session ID  Entities User Feedback  \\\n",
              "0  4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4     event      negative   \n",
              "1  74c97616-9df6-460d-991d-c6f6f6ae5354  location       neutral   \n",
              "2  f3034d75-d552-4a6c-8c73-0f6b441a7bdf     event      negative   \n",
              "3  46c7bf6a-1da6-4e27-baf5-a138f1e0a1b2   service      negative   \n",
              "4  2487c6ce-65c1-48a4-a76f-0aa6a1e92dda   service       neutral   \n",
              "\n",
              "  Conversation Outcome       User Profile Channel/Platform Language  \\\n",
              "0           incomplete  Annette Henderson     social media   German   \n",
              "1     specific outcome     Nicholas Haney       mobile app  Chinese   \n",
              "2           incomplete        David Smith     website chat  Spanish   \n",
              "3           incomplete       Susan Wilson     website chat  English   \n",
              "4     specific outcome    Jennifer Harmon       mobile app  Spanish   \n",
              "\n",
              "  User Emotion/Sentiment  Location         User Segment  \n",
              "0               confused    Sydney  returning customers  \n",
              "1             frustrated    London  returning customers  \n",
              "2                excited     Tokyo        premium users  \n",
              "3             frustrated    Sydney            new users  \n",
              "4               confused  New York  returning customers  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LawJ3l_4eHze"
      },
      "outputs": [],
      "source": [
        "# Required columns for training\n",
        "columns_needed = [\"User Utterance\", \"Bot Response\", \"Context/Session ID\", \"Entities\"]\n",
        "data = data[columns_needed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WyDSpVVel1f",
        "outputId": "34686ed7-9c2f-40e3-825a-f56230018e4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Input: Context: \n",
            "User: Charge bar between follow student.\n",
            "Bot:\n",
            "Sample Target: Important law into large example range. Player seem force with partner sometimes happen southern.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Preprocessing Function\n",
        "def preprocess_data_with_context(data):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    context_mapping = {}\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        user_utterance = row[\"User Utterance\"]\n",
        "        bot_response = row[\"Bot Response\"]\n",
        "        session_id = row[\"Context/Session ID\"]\n",
        "\n",
        "        # Maintain a session context\n",
        "        if session_id not in context_mapping:\n",
        "            context_mapping[session_id] = []\n",
        "\n",
        "        # Build context\n",
        "        session_context = \" \".join(context_mapping[session_id][-3:])  # Limit context to last 3 exchanges\n",
        "        input_text = f\"Context: {session_context}\\nUser: {user_utterance}\\nBot:\"\n",
        "        target_text = bot_response\n",
        "\n",
        "        # Update context for the session\n",
        "        context_mapping[session_id].append(f\"User: {user_utterance} Bot: {bot_response}\")\n",
        "\n",
        "        inputs.append(input_text)\n",
        "        targets.append(target_text)\n",
        "\n",
        "    return inputs, targets\n",
        "\n",
        "# Preprocess data\n",
        "questions, answers = preprocess_data_with_context(data)\n",
        "\n",
        "# Example of tokenized input\n",
        "print(f\"Sample Input: {questions[0]}\")\n",
        "print(f\"Sample Target: {answers[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3vxYiZqexK0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer for GPT-2\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Set the padding token to be the EOS token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Tokenize the dataset for GPT-2\n",
        "def tokenize_dataset(questions, answers, tokenizer, max_length=512):\n",
        "    input_ids = []\n",
        "    target_ids = []\n",
        "\n",
        "    for i, q in enumerate(questions):\n",
        "        # Tokenize input and output\n",
        "        tokenized_input = tokenizer(\n",
        "            q, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
        "        ).input_ids.squeeze()\n",
        "        tokenized_output = tokenizer(\n",
        "            answers[i], max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
        "        ).input_ids.squeeze()\n",
        "\n",
        "        input_ids.append(tokenized_input)\n",
        "        target_ids.append(tokenized_output)\n",
        "\n",
        "    return input_ids, target_ids\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_inputs, tokenized_targets = tokenize_dataset(questions, answers, tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifEihHBFflgF",
        "outputId": "73b54a1a-9e3c-421b-cec3-1f5d443d9bd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Avg. Training Loss: 0.1927\n",
            "Epoch 2/3 - Avg. Training Loss: 0.1724\n",
            "Epoch 3/3 - Avg. Training Loss: 0.1715\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, AdamW\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as pad token\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv(\"/content/chatbot_dataset.csv\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_data_with_context(data):\n",
        "    questions = data['User Utterance'].tolist()\n",
        "    answers = data['Bot Response'].tolist()\n",
        "    return questions, answers\n",
        "\n",
        "questions, answers = preprocess_data_with_context(data)\n",
        "\n",
        "# Define the dataset class\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, questions, answers, tokenizer, max_length=512):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.questions[idx]\n",
        "        target_text = self.answers[idx]\n",
        "\n",
        "        # Tokenize inputs and targets\n",
        "        input_ids = self.tokenizer(input_text, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids.squeeze()\n",
        "        target_ids = self.tokenizer(target_text, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids.squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"labels\": target_ids\n",
        "        }\n",
        "\n",
        "# Create the dataset\n",
        "dataset = ChatDataset(questions, answers, tokenizer)\n",
        "\n",
        "# Load the pre-trained GPT-2 model\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Define TensorBoard writer\n",
        "writer = SummaryWriter(log_dir=\"./logs\")\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-chatbot\",  # Save model checkpoints\n",
        "    num_train_epochs=3,  # Number of epochs\n",
        "    per_device_train_batch_size=8,  # Batch size\n",
        "    save_steps=500,  # Save checkpoints every 500 steps\n",
        "    save_total_limit=2,  # Keep only the last 2 checkpoints\n",
        "    logging_dir=\"./logs\",  # Directory to save logs\n",
        "    logging_steps=50,  # Log every 50 steps\n",
        "    evaluation_strategy=\"no\",  # Disable evaluation\n",
        "    disable_tqdm=False  # Enable progress bars\n",
        ")\n",
        "\n",
        "# Initialize AdamW optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Define the Trainer class\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,  # The dataset for training\n",
        ")\n",
        "\n",
        "# Custom training loop with TensorBoard logging\n",
        "for epoch in range(training_args.num_train_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(trainer.get_train_dataloader()):\n",
        "        # Forward pass\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Manually handle the optimizer step\n",
        "        optimizer.zero_grad()  # Reset gradients after each step\n",
        "\n",
        "        # Log loss to TensorBoard\n",
        "        if step % training_args.logging_steps == 0:\n",
        "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(trainer.get_train_dataloader()) + step)\n",
        "\n",
        "    avg_train_loss = total_loss / len(trainer.get_train_dataloader())\n",
        "    print(f\"Epoch {epoch + 1}/{training_args.num_train_epochs} - Avg. Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "# Save the trained model and tokenizer\n",
        "model.save_pretrained(\"./gpt2-chatbot\")\n",
        "tokenizer.save_pretrained(\"./gpt2-chatbot\")\n",
        "\n",
        "# Close the TensorBoard writer\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAeXvsXfg1YP",
        "outputId": "cb1dd322-c78b-49c9-a648-a784bfe8f79d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: I want to ask something\n",
            "Bot: I want to ask something..\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2-chatbot\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"./gpt2-chatbot\")\n",
        "\n",
        "# Function to generate a response based on user input\n",
        "def generate_response(input_text, model, tokenizer, max_length=50):\n",
        "    # Encode the input text to token ids\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate a response from the model\n",
        "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_p=0.92, temperature=0.7)\n",
        "\n",
        "    # Decode the generated response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Test the model\n",
        "user_input = \"I want to ask something\"\n",
        "response = generate_response(user_input, model, tokenizer)\n",
        "\n",
        "print(f\"User: {user_input}\")\n",
        "print(f\"Bot: {response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1rQZkRI1HA-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
